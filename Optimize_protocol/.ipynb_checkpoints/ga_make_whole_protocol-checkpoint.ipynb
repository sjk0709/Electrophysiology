{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386f4ab6-17d1-4c32-83c2-06b36613beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Lib')\n",
    "sys.path.append('../Models')\n",
    "sys.path.append('../Protocols')\n",
    "from cell_models import kernik, protocols, paci_2018\n",
    "\n",
    "import mod_protocols\n",
    "import protocol_lib\n",
    "import mod_kernik as kernik\n",
    "import mod_trace as trace\n",
    "from Models.br1977 import BR1977\n",
    "from ord2011 import ORD2011\n",
    "import model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c873c35b-d9fe-4498-924c-ab7b25840487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace(model, protocol, prestep):\n",
    "    prestep_protocol = protocol_lib.VoltageClampProtocol([protocol_lib.VoltageClampStep(voltage=-80.0, duration=prestep)])\n",
    "    model.generate_response(prestep_protocol, is_no_ion_selective=False)\n",
    "    model.y_ss = model.y[:, -1]\n",
    "    response_trace = model.generate_response(protocol, is_no_ion_selective=False)\n",
    "    return response_trace\n",
    "\n",
    "\n",
    "def get_long_protocol(individual_dictionary, holding_step):\n",
    "    all_steps = []\n",
    "    holding_step = protocol_lib.VoltageClampStep(-80, holding_step)\n",
    "    \n",
    "    for current, protocol in individual_dictionary.items():\n",
    "        all_steps.append(holding_step)\n",
    "        all_steps += protocol.steps\n",
    "        \n",
    "    long_protocol = protocol_lib.VoltageClampProtocol(all_steps)\n",
    "    return long_protocol\n",
    "\n",
    "\n",
    "def remove_start_of_protocol(protocol, removal_time_step):\n",
    "    vc_segment_endpoints = protocol.get_voltage_change_endpoints()\n",
    "\n",
    "    is_found = False\n",
    "    i = 0\n",
    "    while not is_found:\n",
    "        if removal_time_step < vc_segment_endpoints[i]:\n",
    "            max_segment_idx = i\n",
    "            is_found = True\n",
    "        i += 1\n",
    "\n",
    "    new_start_voltage = protocol.get_voltage_at_time(removal_time_step)\n",
    "    new_duration = (vc_segment_endpoints[max_segment_idx] - removal_time_step)\n",
    "\n",
    "    #TODO make separate function and call from remove_end..()\n",
    "    if isinstance(protocol.steps[max_segment_idx], protocol_lib.VoltageClampRamp) or isinstance(protocol.steps[max_segment_idx], mod_protocols.VoltageClampRamp):\n",
    "        new_final_voltage = protocol.steps[max_segment_idx].voltage_end\n",
    "        new_segment = protocol_lib.VoltageClampRamp( new_start_voltage, new_final_voltage, new_duration)\n",
    "    else:\n",
    "        new_start_voltage = protocol.steps[max_segment_idx].voltage\n",
    "        new_segment = protocol_lib.VoltageClampStep( new_start_voltage, new_duration)\n",
    "\n",
    "    new_protocol = protocol_lib.VoltageClampProtocol( [new_segment] + protocol.steps[(max_segment_idx + 1):])\n",
    "\n",
    "    return new_protocol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def shorten_protocol_start(protocol, start_time, prestep, window, step_size, max_contribution,\n",
    "                           current_name, acceptable_change, model_name, removal_time_step=200,\n",
    "                           scale=1):\n",
    "    \n",
    "    min_acceptable_current = max_contribution * acceptable_change\n",
    "    \n",
    "    last_protocol = None\n",
    "    while (max_contribution > min_acceptable_current).values[0]:\n",
    "        if protocol.get_voltage_change_endpoints()[-1] <= removal_time_step:\n",
    "            return protocol\n",
    "\n",
    "#         print(max_contribution)\n",
    "        last_protocol = copy.copy(protocol)\n",
    "        \n",
    "        protocol = remove_start_of_protocol( protocol, removal_time_step=removal_time_step)\n",
    "\n",
    "        max_currents = get_max_currents( protocol, prestep=prestep, window=window, step_size=step_size, scale=scale, model_name=model_name)\n",
    "        max_contribution = max_currents[max_currents[\"Current\"]==current_name][\"Contribution\"]\n",
    "\n",
    "    return last_protocol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_protocol_without_end(protocol, start_time, window, extra_time, scale=1):\n",
    "    window = window/scale\n",
    "    extra_time = extra_time/scale\n",
    "\n",
    "    vc_segment_endpoints = protocol.get_voltage_change_endpoints()\n",
    "\n",
    "    cutoff_time = scale * (start_time + extra_time)\n",
    "\n",
    "    if cutoff_time >  vc_segment_endpoints[-1]:        \n",
    "        return protocol\n",
    "\n",
    "    is_found = False\n",
    "    i = 0\n",
    "    while not is_found:\n",
    "        if cutoff_time < vc_segment_endpoints[i]:\n",
    "            max_segment_idx = i\n",
    "            is_found = True\n",
    "        i += 1\n",
    "       \n",
    "    new_duration = (cutoff_time - vc_segment_endpoints[max_segment_idx-1])\n",
    "    if new_duration <= 0.0:\n",
    "        print(\"Warning ......................................................\")\n",
    "\n",
    "    if isinstance(protocol.steps[max_segment_idx], protocol_lib.VoltageClampRamp) or isinstance(protocol.steps[max_segment_idx], mod_protocols.VoltageClampRamp):\n",
    "        new_start_voltage = protocol.steps[max_segment_idx].voltage_start\n",
    "        new_final_voltage = protocol.get_voltage_at_time(cutoff_time)\n",
    "        new_segment = protocol_lib.VoltageClampRamp( new_start_voltage, new_final_voltage, new_duration)\n",
    "    else:\n",
    "        new_start_voltage = protocol.steps[max_segment_idx].voltage\n",
    "        new_segment = protocol_lib.VoltageClampStep( new_start_voltage, new_duration)\n",
    "\n",
    "     \n",
    "    new_protocol = protocol_lib.VoltageClampProtocol( protocol.steps[0:max_segment_idx] + [new_segment])\n",
    "\n",
    "    return new_protocol\n",
    "\n",
    "\n",
    "\n",
    "def get_max_currents(vc_protocol, prestep, window, step_size, model_name, scale=1):\n",
    "    if model_name == 'Paci':\n",
    "        baseline_paci= paci_2018.PaciModel(is_exp_artefact=True)\n",
    "        i_trace = get_trace(baseline_paci, vc_protocol, prestep=prestep)\n",
    "    elif model_name == 'BR1977':\n",
    "        model = BR1977(vc_protocol)\n",
    "        i_trace = model_response.get_model_response_JK(model, vc_protocol, prestep=prestep)        \n",
    "    elif model_name == 'ORD2011':\n",
    "        model = ORD2011(vc_protocol)\n",
    "        i_trace = model_response.get_model_response_JK(model, vc_protocol, prestep=prestep)        \n",
    "    elif model_name == 'OHara2017':\n",
    "        model = \"../mmt-model-files/ohara-cipa-v1-2017_JK-v1.mmt\"          \n",
    "        i_trace = model_response.get_model_response_with_myokit( model, vc_protocol, prestep=prestep )           \n",
    "    else:\n",
    "        baseline_kernik = kernik.KernikModel(is_exp_artefact=True)\n",
    "        i_trace = get_trace(baseline_kernik, vc_protocol, prestep=prestep)        \n",
    "        \n",
    "    max_currents = i_trace.current_response_info.get_max_current_contributions(\n",
    "            i_trace.t, window=window/scale, step_size=step_size/scale)\n",
    "\n",
    "    return max_currents\n",
    "\n",
    "\n",
    "def shorten_protocol(best_individual, current_name, only_end, model_name, window=10, step_size=5, prestep=2000):\n",
    "    vc_protocol = best_individual.protocol\n",
    "    length_of_protocol = vc_protocol.get_voltage_change_endpoints()[-1]\n",
    "\n",
    "    scale = 1\n",
    "\n",
    "    max_currents = get_max_currents(vc_protocol, prestep=prestep, window=window, step_size=step_size, \n",
    "                                    model_name=model_name, scale=scale)    \n",
    "#     print(max_currents[max_currents[\"Current\"]==current_name])     # 0    I_Na      0.976547       860.0     870.0\n",
    "    start_time = float(max_currents[max_currents[\"Current\"]==current_name][\"Time Start\"])\n",
    "    shortened_protocol = get_protocol_without_end( vc_protocol, start_time, window, extra_time=100, scale=scale)\n",
    "\n",
    "    if not only_end:\n",
    "        max_contribution = max_currents[max_currents[\"Current\"]==current_name][\"Contribution\"]\n",
    "        if current_name == \"I_Kr\" or \"IKr\" or \"ikr.IKr\":\n",
    "            accepted_threshold = .99\n",
    "        else: \n",
    "            accepted_threshold = .95\n",
    "        shortened_protocol = shorten_protocol_start(shortened_protocol, start_time, prestep, window, step_size, max_contribution,\n",
    "                                                    current_name, acceptable_change=accepted_threshold, scale=scale,\n",
    "                                                    model_name=model_name)\n",
    "\n",
    "    print(\n",
    "        f'Protocol length of {current_name} decreased from {length_of_protocol} to {shortened_protocol.get_voltage_change_endpoints()[-1]}.')\n",
    "    return shortened_protocol\n",
    "\n",
    "\n",
    "\n",
    "def get_high_fitness(ga_result):\n",
    "    best_individual = ga_result.generations[0][0]\n",
    "\n",
    "    for i, gen in enumerate(ga_result.generations):\n",
    "        best_in_gen = ga_result.get_high_fitness_individual(i)\n",
    "        if best_in_gen.fitness > best_individual.fitness:\n",
    "            best_individual = best_in_gen\n",
    "\n",
    "    return best_individual\n",
    "\n",
    "\n",
    "def make_shortened_results(trial_conditions, only_end, \n",
    "                           holding_step, prestep, window, step_size, \n",
    "                           with_artefact=False, model_name='ORD2011', \n",
    "                           currents=['I_Na', 'I_NaL', 'I_to', 'I_CaL', 'I_Kr', 'I_Ks', 'I_K1' ] ):\n",
    "        \n",
    "    folder = f\"ga_results/{trial_conditions}\"\n",
    "\n",
    "    original_protocols = {}\n",
    "    shortened_protocols = {}\n",
    "\n",
    "    for current in currents:\n",
    "        ga_result = pickle.load(open(f'{folder}/ga_results_{current}_a{with_artefact}', 'rb'))\n",
    "        best_individual = get_high_fitness(ga_result)        \n",
    "        shortened_protocols[current] = shorten_protocol(best_individual, \n",
    "                                                        window=window, \n",
    "                                                        prestep=prestep,\n",
    "                                                        current_name=current,\n",
    "                                                        only_end=only_end, \n",
    "                                                        model_name=model_name)\n",
    "        original_protocols[current] = best_individual.protocol\n",
    "        \n",
    "        pickle.dump(shortened_protocols[current], open(f\"{folder}/short_{current}_p{prestep}_oe{only_end}_a{with_artefact}.pkl\", 'wb'))\n",
    "\n",
    "    new_long_protocol = get_long_protocol(shortened_protocols, holding_step)\n",
    "    scale = 1\n",
    "    shortened_max_currents = get_max_currents( new_long_protocol, prestep=prestep, window=window, step_size=step_size,\n",
    "                                               model_name=model_name, scale=scale)\n",
    "\n",
    "    print(f\"The shortened_max_currents are {shortened_max_currents}\")\n",
    "    shortened_max_currents.to_csv(\n",
    "            f\"{folder}/{trial_conditions}_h{holding_step}_p{prestep}_oe{only_end}_a{with_artefact}.csv\")\n",
    "\n",
    "    pickle.dump(new_long_protocol, open(f\"{folder}/{trial_conditions}_h{holding_step}_p{prestep}_oe{only_end}_a{with_artefact}.pkl\", 'wb'))\n",
    "    \n",
    "#     return shortened_protocols, new_long_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294e5741-f909-4229-af43-3401d61687da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol length of INa decreased from 695.1252008306025 to 190.0.\n",
      "Protocol length of INaL decreased from 3091.5563615597794 to 1920.0.\n",
      "Protocol length of Ito decreased from 3384.0718676063616 to 1655.0.\n",
      "Protocol length of ICaL decreased from 2868.6198992903533 to 615.0000000000001.\n",
      "Protocol length of IKr decreased from 3095.4369812034583 to 295.4369812034586.\n",
      "Protocol length of IKs decreased from 2773.3848121011124 to 2200.0.\n",
      "Protocol length of IK1 decreased from 3316.2762607823865 to 55.000000000000114.\n",
      "The shortened_max_currents are      Current  Contribution  Time Start  Time End\n",
      "0      i_ion      0.000000         0.0      10.0\n",
      "1        INa      0.484063       590.0     600.0\n",
      "2       INaL      0.451103      3010.0    3020.0\n",
      "3        Ito      0.327205      5165.0    5175.0\n",
      "4       ICaL      0.448371      6280.0    6290.0\n",
      "5      ICaNa      0.077245      6980.0    6990.0\n",
      "6       ICaK      0.188741      7690.0    7700.0\n",
      "7        IKr      0.437855      7085.0    7095.0\n",
      "8        IKs      0.307480      9775.0    9785.0\n",
      "9        IK1      0.499091      2925.0    2935.0\n",
      "10     INaCa      0.107569      7065.0    7075.0\n",
      "11  INaCa_ss      0.115809      1215.0    1225.0\n",
      "12      INaK      0.058143      5805.0    5815.0\n",
      "13       IKb      0.133482      5155.0    5165.0\n",
      "14      INab      0.006294      2990.0    3000.0\n",
      "15      ICab      0.006403      2990.0    3000.0\n",
      "16      IpCa      0.000077      7065.0    7075.0\n",
      "--- 269.42598700523376 seconds ---\n"
     ]
    }
   ],
   "source": [
    "trial_conditions = \"OHara2017_360_100_4_-121_61_10_5\"\n",
    "prestep = 5000\n",
    "window = 10\n",
    "step_size = 5\n",
    "holding_step = 500\n",
    "only_end = False\n",
    "with_artefact =False\n",
    "model_name = trial_conditions.split('_')[0]\n",
    "\n",
    "currents = ['I_Na', 'I_Kr', 'I_Ks', 'I_To', 'I_CaL', 'I_K1', 'I_NaL' ]   \n",
    "if model_name=='BR1977':\n",
    "    with_artefact = False\n",
    "    currents = ['I_Na', 'I_si', 'I_K1', 'I_x1']\n",
    "elif model_name=='Kernik':        \n",
    "    with_artefact = True\n",
    "    currents = ['I_Na', 'I_Kr', 'I_Ks', 'I_To', 'I_F', 'I_CaL', 'I_K1'] \n",
    "elif model_name=='OHara2017':        \n",
    "    with_artefact = False\n",
    "    currents = ['INa', 'INaL', 'Ito', 'ICaL', 'IKr', 'IKs', 'IK1']\n",
    "\n",
    "start_time = time.time()\n",
    "make_shortened_results(trial_conditions, only_end=only_end, holding_step=holding_step, \n",
    "                       prestep=prestep, window=window, step_size=step_size,\n",
    "                       with_artefact=with_artefact, model_name=model_name, currents=currents)\n",
    "print(\"--- %s seconds ---\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d7c1e-ac95-48ca-8ee1-686b4f1bb0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
