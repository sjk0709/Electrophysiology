{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386f4ab6-17d1-4c32-83c2-06b36613beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../Lib')\n",
    "sys.path.append('../Models')\n",
    "sys.path.append('../Protocols')\n",
    "from cell_models import kernik, protocols, paci_2018\n",
    "\n",
    "import mod_protocols\n",
    "import protocol_lib\n",
    "import mod_kernik as kernik\n",
    "import mod_trace as trace\n",
    "from Models.br1977 import BR1977\n",
    "from ord2011 import ORD2011\n",
    "import model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c873c35b-d9fe-4498-924c-ab7b25840487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace(model, protocol, prestep):\n",
    "    prestep_protocol = protocol_lib.VoltageClampProtocol([protocol_lib.VoltageClampStep(voltage=-80.0, duration=prestep)])\n",
    "    model.generate_response(prestep_protocol, is_no_ion_selective=False)\n",
    "    model.y_ss = model.y[:, -1]\n",
    "    response_trace = model.generate_response(protocol, is_no_ion_selective=False)\n",
    "    return response_trace\n",
    "\n",
    "\n",
    "def get_long_protocol(individual_dictionary, holding_step):\n",
    "    all_steps = []\n",
    "    holding_step = protocol_lib.VoltageClampStep(-80, holding_step)\n",
    "    \n",
    "    for current, protocol in individual_dictionary.items():\n",
    "        all_steps.append(holding_step)\n",
    "        all_steps += protocol.steps\n",
    "        \n",
    "    long_protocol = protocol_lib.VoltageClampProtocol(all_steps)\n",
    "    return long_protocol\n",
    "\n",
    "\n",
    "def remove_start_of_protocol(protocol, removal_time_step):\n",
    "    vc_segment_endpoints = protocol.get_voltage_change_endpoints()\n",
    "\n",
    "    is_found = False\n",
    "    i = 0\n",
    "    while not is_found:\n",
    "        if removal_time_step < vc_segment_endpoints[i]:\n",
    "            max_segment_idx = i\n",
    "            is_found = True\n",
    "        i += 1\n",
    "\n",
    "    new_start_voltage = protocol.get_voltage_at_time(removal_time_step)\n",
    "    new_duration = (vc_segment_endpoints[max_segment_idx] - removal_time_step)\n",
    "\n",
    "    #TODO make separate function and call from remove_end..()\n",
    "    if isinstance(protocol.steps[max_segment_idx], protocol_lib.VoltageClampRamp) or isinstance(protocol.steps[max_segment_idx], mod_protocols.VoltageClampRamp):\n",
    "        new_final_voltage = protocol.steps[max_segment_idx].voltage_end\n",
    "        new_segment = protocol_lib.VoltageClampRamp( new_start_voltage, new_final_voltage, new_duration)\n",
    "    else:\n",
    "        new_start_voltage = protocol.steps[max_segment_idx].voltage\n",
    "        new_segment = protocol_lib.VoltageClampStep( new_start_voltage, new_duration)\n",
    "\n",
    "    new_protocol = protocol_lib.VoltageClampProtocol( [new_segment] + protocol.steps[(max_segment_idx + 1):])\n",
    "\n",
    "    return new_protocol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def shorten_protocol_start(protocol, start_time, prestep, window, step_size, max_contribution,\n",
    "                           current_name, acceptable_change, model_name, removal_time_step=200,\n",
    "                           scale=1):\n",
    "    \n",
    "    min_acceptable_current = max_contribution * acceptable_change\n",
    "    \n",
    "    last_protocol = None\n",
    "    while (max_contribution > min_acceptable_current).values[0]:\n",
    "        if protocol.get_voltage_change_endpoints()[-1] <= removal_time_step:\n",
    "            return protocol\n",
    "\n",
    "#         print(max_contribution)\n",
    "        last_protocol = copy.copy(protocol)\n",
    "        \n",
    "        protocol = remove_start_of_protocol( protocol, removal_time_step=removal_time_step)\n",
    "\n",
    "        max_currents = get_max_currents( protocol, prestep=prestep, window=window, step_size=step_size, scale=scale, model_name=model_name)\n",
    "        max_contribution = max_currents[max_currents[\"Current\"]==current_name][\"Contribution\"]\n",
    "\n",
    "    return last_protocol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_protocol_without_end(protocol, start_time, window, extra_time, scale=1):\n",
    "    window = window/scale\n",
    "    extra_time = extra_time/scale\n",
    "\n",
    "    vc_segment_endpoints = protocol.get_voltage_change_endpoints()\n",
    "\n",
    "    cutoff_time = scale * (start_time + extra_time)\n",
    "\n",
    "    if cutoff_time >  vc_segment_endpoints[-1]:        \n",
    "        return protocol\n",
    "\n",
    "    is_found = False\n",
    "    i = 0\n",
    "    while not is_found:\n",
    "        if cutoff_time < vc_segment_endpoints[i]:\n",
    "            max_segment_idx = i\n",
    "            is_found = True\n",
    "        i += 1\n",
    "       \n",
    "    new_duration = (cutoff_time - vc_segment_endpoints[max_segment_idx-1])\n",
    "    if new_duration <= 0.0:\n",
    "        print(\"Warning ......................................................\")\n",
    "\n",
    "    if isinstance(protocol.steps[max_segment_idx], protocol_lib.VoltageClampRamp) or isinstance(protocol.steps[max_segment_idx], mod_protocols.VoltageClampRamp):\n",
    "        new_start_voltage = protocol.steps[max_segment_idx].voltage_start\n",
    "        new_final_voltage = protocol.get_voltage_at_time(cutoff_time)\n",
    "        new_segment = protocol_lib.VoltageClampRamp( new_start_voltage, new_final_voltage, new_duration)\n",
    "    else:\n",
    "        new_start_voltage = protocol.steps[max_segment_idx].voltage\n",
    "        new_segment = protocol_lib.VoltageClampStep( new_start_voltage, new_duration)\n",
    "\n",
    "     \n",
    "    new_protocol = protocol_lib.VoltageClampProtocol( protocol.steps[0:max_segment_idx] + [new_segment])\n",
    "\n",
    "    return new_protocol\n",
    "\n",
    "\n",
    "\n",
    "def get_max_currents(vc_protocol, prestep, window, step_size, model_name, scale=1):\n",
    "    if model_name == 'Paci':\n",
    "        baseline_paci= paci_2018.PaciModel(is_exp_artefact=True)\n",
    "        i_trace = get_trace(baseline_paci, vc_protocol, prestep=prestep)\n",
    "    elif model_name == 'BR1977':\n",
    "        model = BR1977(vc_protocol)\n",
    "        i_trace = model_response.get_model_response_JK(model, vc_protocol, prestep=prestep)        \n",
    "    elif model_name == 'ORD2011':\n",
    "        model = ORD2011(vc_protocol)\n",
    "        i_trace = model_response.get_model_response_JK(model, vc_protocol, prestep=prestep)        \n",
    "    elif model_name == 'OHara2017':\n",
    "        model = \"../mmt-model-files/ohara-cipa-v1-2017_JK-v1.mmt\"          \n",
    "        i_trace = model_response.get_model_response_with_myokit( model, vc_protocol, prestep=prestep )           \n",
    "    else:\n",
    "        baseline_kernik = kernik.KernikModel(is_exp_artefact=True)\n",
    "        i_trace = get_trace(baseline_kernik, vc_protocol, prestep=prestep)        \n",
    "        \n",
    "    max_currents = i_trace.current_response_info.get_max_current_contributions(\n",
    "            i_trace.t, window=window/scale, step_size=step_size/scale)\n",
    "\n",
    "    return max_currents\n",
    "\n",
    "\n",
    "def shorten_protocol(best_individual, current_name, only_end, model_name, window=10, step_size=5, prestep=2000):\n",
    "    vc_protocol = best_individual.protocol\n",
    "    length_of_protocol = vc_protocol.get_voltage_change_endpoints()[-1]\n",
    "\n",
    "    scale = 1\n",
    "\n",
    "    max_currents = get_max_currents(vc_protocol, prestep=prestep, window=window, step_size=step_size, \n",
    "                                    model_name=model_name, scale=scale)    \n",
    "#     print(max_currents[max_currents[\"Current\"]==current_name])     # 0    I_Na      0.976547       860.0     870.0\n",
    "    start_time = float(max_currents[max_currents[\"Current\"]==current_name][\"Time Start\"])\n",
    "    shortened_protocol = get_protocol_without_end( vc_protocol, start_time, window, extra_time=100, scale=scale)\n",
    "\n",
    "    if not only_end:\n",
    "        max_contribution = max_currents[max_currents[\"Current\"]==current_name][\"Contribution\"]\n",
    "        if current_name == \"I_Kr\" or \"IKr\" or \"ikr.IKr\":\n",
    "            accepted_threshold = .99\n",
    "        else: \n",
    "            accepted_threshold = .95\n",
    "        shortened_protocol = shorten_protocol_start(shortened_protocol, start_time, prestep, window, step_size, max_contribution,\n",
    "                                                    current_name, acceptable_change=accepted_threshold, scale=scale,\n",
    "                                                    model_name=model_name)\n",
    "\n",
    "    print(\n",
    "        f'Protocol length of {current_name} decreased from {length_of_protocol} to {shortened_protocol.get_voltage_change_endpoints()[-1]}.')\n",
    "    return shortened_protocol\n",
    "\n",
    "\n",
    "\n",
    "def get_high_fitness(ga_result):\n",
    "    best_individual = ga_result.generations[0][0]\n",
    "\n",
    "    for i, gen in enumerate(ga_result.generations):\n",
    "        best_in_gen = ga_result.get_high_fitness_individual(i)\n",
    "        if best_in_gen.fitness > best_individual.fitness:\n",
    "            best_individual = best_in_gen\n",
    "\n",
    "    return best_individual\n",
    "\n",
    "\n",
    "def make_shortened_results(trial_conditions, only_end, \n",
    "                           holding_step, prestep, window, step_size, \n",
    "                           with_artefact=False, model_name='ORD2011', \n",
    "                           currents=['I_Na', 'I_NaL', 'I_to', 'I_CaL', 'I_Kr', 'I_Ks', 'I_K1' ] ):\n",
    "        \n",
    "    folder = f\"ga_results/{trial_conditions}\"\n",
    "\n",
    "    original_protocols = {}\n",
    "    shortened_protocols = {}\n",
    "\n",
    "    for current in currents:\n",
    "        ga_result = pickle.load(open(f'{folder}/ga_results_{current}_a{with_artefact}', 'rb'))\n",
    "        best_individual = get_high_fitness(ga_result)        \n",
    "        shortened_protocols[current] = shorten_protocol(best_individual, \n",
    "                                                        window=window, \n",
    "                                                        prestep=prestep,\n",
    "                                                        current_name=current,\n",
    "                                                        only_end=only_end, \n",
    "                                                        model_name=model_name)\n",
    "        original_protocols[current] = best_individual.protocol\n",
    "        \n",
    "        pickle.dump(shortened_protocols[current], open(f\"{folder}/short_{current}_p{prestep}_oe{only_end}_a{with_artefact}.pkl\", 'wb'))\n",
    "\n",
    "    new_long_protocol = get_long_protocol(shortened_protocols, holding_step)\n",
    "    scale = 1\n",
    "    shortened_max_currents = get_max_currents( new_long_protocol, prestep=prestep, window=window, step_size=step_size,\n",
    "                                               model_name=model_name, scale=scale)\n",
    "\n",
    "    print(f\"The shortened_max_currents are {shortened_max_currents}\")\n",
    "    shortened_max_currents.to_csv(\n",
    "            f\"{folder}/{trial_conditions}_h{holding_step}_p{prestep}_oe{only_end}_a{with_artefact}.csv\")\n",
    "\n",
    "    pickle.dump(new_long_protocol, open(f\"{folder}/{trial_conditions}_h{holding_step}_p{prestep}_oe{only_end}_a{with_artefact}.pkl\", 'wb'))\n",
    "    \n",
    "#     return shortened_protocols, new_long_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294e5741-f909-4229-af43-3401d61687da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol length of INa decreased from 1624.9452210801317 to 675.0.\n",
      "Protocol length of INaL decreased from 3097.286398561765 to 1845.0.\n",
      "Protocol length of Ito decreased from 2036.2435894706373 to 625.0.\n",
      "Protocol length of ICaL decreased from 2356.114506800531 to 400.0.\n",
      "Protocol length of IKr decreased from 2915.9354931356856 to 315.9354931356857.\n",
      "Protocol length of IKs decreased from 3664.0570707522643 to 2475.0.\n",
      "Protocol length of IK1 decreased from 3682.047079524957 to 45.0.\n",
      "The shortened_max_currents are      Current  Contribution  Time Start  Time End\n",
      "0      i_ion      0.000000         0.0      10.0\n",
      "1        INa      0.487345      1075.0    1085.0\n",
      "2       INaL      0.440366      3420.0    3430.0\n",
      "3        Ito      0.327062      4545.0    4555.0\n",
      "4       ICaL      0.450934      5445.0    5455.0\n",
      "5      ICaNa      0.096036      4555.0    4565.0\n",
      "6       ICaK      0.183363      6875.0    6885.0\n",
      "7        IKr      0.438879      6305.0    6315.0\n",
      "8        IKs      0.315236      9235.0    9245.0\n",
      "9        IK1      0.499086      3340.0    3350.0\n",
      "10     INaCa      0.154747      6060.0    6070.0\n",
      "11  INaCa_ss      0.140599      1690.0    1700.0\n",
      "12      INaK      0.282920      6060.0    6070.0\n",
      "13       IKb      0.140830      4535.0    4545.0\n",
      "14      INab      0.069126      6060.0    6070.0\n",
      "15      ICab      0.078084      6060.0    6070.0\n",
      "16      IpCa      0.000330      6060.0    6070.0\n",
      "--- 219.66647386550903 seconds ---\n"
     ]
    }
   ],
   "source": [
    "trial_conditions = \"OHara2017_360_100_4_-121_61_10_5\"\n",
    "prestep = 5000\n",
    "window = 10\n",
    "step_size = 5\n",
    "holding_step = 500\n",
    "only_end = False\n",
    "with_artefact =False\n",
    "model_name = trial_conditions.split('_')[0]\n",
    "\n",
    "currents = ['I_Na', 'I_Kr', 'I_Ks', 'I_To', 'I_CaL', 'I_K1', 'I_NaL' ]   \n",
    "if model_name=='BR1977':\n",
    "    with_artefact = False\n",
    "    currents = ['I_Na', 'I_si', 'I_K1', 'I_x1']\n",
    "elif model_name=='Kernik':        \n",
    "    with_artefact = True\n",
    "    currents = ['I_Na', 'I_Kr', 'I_Ks', 'I_To', 'I_F', 'I_CaL', 'I_K1'] \n",
    "elif model_name=='OHara2017':        \n",
    "    with_artefact = False\n",
    "    currents = ['INa', 'INaL', 'Ito', 'ICaL', 'IKr', 'IKs', 'IK1']\n",
    "\n",
    "start_time = time.time()\n",
    "make_shortened_results(trial_conditions, only_end=only_end, holding_step=holding_step, \n",
    "                       prestep=prestep, window=window, step_size=step_size,\n",
    "                       with_artefact=with_artefact, model_name=model_name, currents=currents)\n",
    "print(\"--- %s seconds ---\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d7c1e-ac95-48ca-8ee1-686b4f1bb0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
